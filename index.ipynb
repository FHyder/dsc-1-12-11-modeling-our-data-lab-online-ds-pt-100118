{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Our Data - Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction \n",
    "\n",
    "In this lab we'll perform a full linear regression on our data. We'll take a stepwise approach and we'll try to improve our model as we go."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "You will be able to:\n",
    "\n",
    "* Remove predictors with p-values too high and refit the model\n",
    "* Examine and interpret the model results\n",
    "* Split data into training and testing sets\n",
    "* Fit a regression model to the data set using statsmodel library\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build single linear regression models\n",
    "\n",
    "From the previous steps, it is pretty clear that we have quite a few predictors, but there are some issues with them. Linearity with the target \"Weekly_Sales\" wasn't apparent. If that's the case, it's always smart to start small, and go ahead and build linear regression models with just one input at the time. Somewhat like what we've done in section 10, let's look at some statistics for single linear regression models for all our *continuous* variables with the outcome.\n",
    "\n",
    "**Note: for now, we will not use holdout validation, as we're just trying to gauge interpretation and a sense of predictive capacity for each of the candidate predictors**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the cleaned dataset \"walmart_dataset.csv\", and check its contents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('walmart_dataset_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pull up the info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 97839 entries, 0 to 97838\n",
      "Columns: 127 entries, Weekly_Sales to binned_markdown_5_NaN\n",
      "dtypes: bool(1), float64(6), int64(120)\n",
      "memory usage: 94.1 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the output for info is much smaller compared to what we usually see. Because we have so many columns, pandas is intentionally not showing the data types for each column. Let's use `info()` again, but now just on the first 15 columns of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 97839 entries, 0 to 97838\n",
      "Data columns (total 15 columns):\n",
      "Weekly_Sales    97839 non-null float64\n",
      "IsHoliday       97839 non-null bool\n",
      "Size            97839 non-null float64\n",
      "Temperature     97839 non-null float64\n",
      "Fuel_Price      97839 non-null float64\n",
      "CPI             97839 non-null float64\n",
      "Unemployment    97839 non-null float64\n",
      "Store_1         97839 non-null int64\n",
      "Store_10        97839 non-null int64\n",
      "Store_2         97839 non-null int64\n",
      "Store_3         97839 non-null int64\n",
      "Store_4         97839 non-null int64\n",
      "Store_5         97839 non-null int64\n",
      "Store_6         97839 non-null int64\n",
      "Store_7         97839 non-null int64\n",
      "dtypes: bool(1), float64(6), int64(8)\n",
      "memory usage: 10.5 MB\n"
     ]
    }
   ],
   "source": [
    "df.iloc[:,0:15].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that all the columns from store_1 onwards are actually dummies, so categorical variables. Because we stored the data and loaded it in again, this information was lost. Let's make sure they become categorical again. You can write a for-loop to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 97839 entries, 0 to 97838\n",
      "Data columns (total 15 columns):\n",
      "Weekly_Sales    97839 non-null float64\n",
      "IsHoliday       97839 non-null bool\n",
      "Size            97839 non-null float64\n",
      "Temperature     97839 non-null float64\n",
      "Fuel_Price      97839 non-null float64\n",
      "CPI             97839 non-null float64\n",
      "Unemployment    97839 non-null float64\n",
      "Store_1         97839 non-null object\n",
      "Store_10        97839 non-null object\n",
      "Store_2         97839 non-null object\n",
      "Store_3         97839 non-null object\n",
      "Store_4         97839 non-null object\n",
      "Store_5         97839 non-null object\n",
      "Store_6         97839 non-null object\n",
      "Store_7         97839 non-null object\n",
      "dtypes: bool(1), float64(6), object(8)\n",
      "memory usage: 10.5+ MB\n"
     ]
    }
   ],
   "source": [
    "change = list(range(1,11))\n",
    "for i in change:\n",
    "    df[\"Store_\"+ f'{i}'] = df[\"Store_\"+ f'{i}'].astype(str)\n",
    "df.iloc[:,0:15].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure IsHoliday is a categorical variable as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.IsHoliday = df.IsHoliday.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the info again to make sure everything is OK now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 97839 entries, 0 to 97838\n",
      "Data columns (total 15 columns):\n",
      "Weekly_Sales    97839 non-null float64\n",
      "IsHoliday       97839 non-null object\n",
      "Size            97839 non-null float64\n",
      "Temperature     97839 non-null float64\n",
      "Fuel_Price      97839 non-null float64\n",
      "CPI             97839 non-null float64\n",
      "Unemployment    97839 non-null float64\n",
      "Store_1         97839 non-null object\n",
      "Store_10        97839 non-null object\n",
      "Store_2         97839 non-null object\n",
      "Store_3         97839 non-null object\n",
      "Store_4         97839 non-null object\n",
      "Store_5         97839 non-null object\n",
      "Store_6         97839 non-null object\n",
      "Store_7         97839 non-null object\n",
      "dtypes: float64(6), object(9)\n",
      "memory usage: 11.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.iloc[:,0:15].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! you should see that the datatypes have changed to categories now! If you use `.describe` now, you should see only the remaining continuous variables in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use a for-loop to look at some results for each linear regression model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use ordinary least squares in statsmodels at this stage.\n",
    "Import `statsmodels.formula.api` to get started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a loop that for each iteration:\n",
    "* Runs a simple OLS regression between (continuous) independent and dependent variables\n",
    "* Store following values in array for each iteration\n",
    "    * Target variable\n",
    "    * R_squared\n",
    "    * intercept\n",
    "    * slope\n",
    "    * p-value\n",
    "* Comment on each output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Walmart: Weekly_Sales~Size\n",
      "------------------------------\n",
      "['Size', 0.08577198301194777, 17223.235590817574, 7406.227377929049, 0.0]\n",
      "Walmart: Weekly_Sales~Temperature\n",
      "------------------------------\n",
      "['Temperature', 0.0010145286600620196, 17223.235590817378, 805.4831797033963, 2.160985815462691e-23]\n",
      "Walmart: Weekly_Sales~Fuel_Price\n",
      "------------------------------\n",
      "['Fuel_Price', 0.0008029403665875678, 17223.235590817232, 716.5821103232543, 7.649612001141253e-19]\n",
      "Walmart: Weekly_Sales~CPI\n",
      "------------------------------\n",
      "['CPI', 0.039410515354355025, 17223.2355908175, -5020.308120380831, 0.0]\n",
      "Walmart: Weekly_Sales~Unemployment\n",
      "------------------------------\n",
      "['Unemployment', 0.0008517114683159743, 17223.235590816246, 738.0241329746427, 6.825456986258902e-20]\n",
      "Walmart: Weekly_Sales~Dept_1\n",
      "------------------------------\n",
      "['Dept_1', 0.00028597853111089755, 17171.152345009268, 3563.4774032430937, 1.2237705375275502e-07]\n",
      "Walmart: Weekly_Sales~Dept_10\n",
      "------------------------------\n",
      "['Dept_10', 0.002592805698849676, 17066.410223941726, 10729.81613270237, 3.486016548797359e-57]\n",
      "Walmart: Weekly_Sales~Dept_11\n",
      "------------------------------\n",
      "['Dept_11', 0.00012146959971548466, 17189.29142611166, 2322.421769692573, 0.0005659140058280239]\n",
      "Walmart: Weekly_Sales~Dept_12\n",
      "------------------------------\n",
      "['Dept_12', 0.0025908363373273735, 17380.001388148412, -10725.740451086502, 3.8409711011018355e-57]\n",
      "Walmart: Weekly_Sales~Dept_13\n",
      "------------------------------\n",
      "['Dept_13', 0.006517774469599225, 16974.589869514228, 17012.06204657095, 3.7617493490697046e-141]\n",
      "Walmart: Weekly_Sales~Dept_14\n",
      "------------------------------\n",
      "['Dept_14', 5.524356059494195e-06, 17230.47448381375, -495.27695933842074, 0.46223173222236036]\n",
      "Walmart: Weekly_Sales~Dept_16\n",
      "------------------------------\n",
      "['Dept_16', 6.363274847298594e-05, 17198.667485400736, 1680.9222838300243, 0.012590176427461788]\n",
      "Walmart: Weekly_Sales~Dept_17\n",
      "------------------------------\n",
      "['Dept_17', 0.0010374691195611518, 17322.437245277924, -6787.266203320602, 6.950520548998392e-24]\n",
      "Walmart: Weekly_Sales~Dept_18\n",
      "------------------------------\n",
      "['Dept_18', 0.0014130770393785408, 17324.789754690653, -8999.961810851011, 6.115343156308438e-32]\n",
      "Walmart: Weekly_Sales~Dept_19\n",
      "------------------------------\n",
      "['Dept_19', 0.004706861098801807, 17420.84436885258, -15430.0440815411, 2.167120428153414e-102]\n",
      "Walmart: Weekly_Sales~Dept_2\n",
      "------------------------------\n",
      "['Dept_2', 0.021710685455038514, 16769.431827007807, 31048.745767400163, 0.0]\n",
      "Walmart: Weekly_Sales~Dept_20\n",
      "------------------------------\n",
      "['Dept_20', 0.0031361981833631924, 17395.713339729704, -11800.734598472081, 8.389725694629722e-69]\n",
      "Walmart: Weekly_Sales~Dept_21\n",
      "------------------------------\n",
      "['Dept_21', 0.003004965873000698, 17392.066165192053, -11551.198997360993, 5.365264871518507e-66]\n",
      "Walmart: Weekly_Sales~Dept_22\n",
      "------------------------------\n",
      "['Dept_22', 0.000982631378787402, 17319.779891296457, -6605.4530171712995, 1.0466216498783796e-22]\n",
      "Walmart: Weekly_Sales~Dept_23\n",
      "------------------------------\n",
      "['Dept_23', 0.00140935648137408, 17107.61325083756, 7910.751133778286, 7.34751369391285e-32]\n",
      "Walmart: Weekly_Sales~Dept_24\n",
      "------------------------------\n",
      "['Dept_24', 0.0028672431880536475, 17388.151893910326, -11283.38893586945, 4.72332957205697e-63]\n",
      "Walmart: Weekly_Sales~Dept_25\n",
      "------------------------------\n",
      "['Dept_25', 0.001203988022036473, 17330.102293354357, -7311.700216432067, 1.8560560005938183e-27]\n",
      "Walmart: Weekly_Sales~Dept_26\n",
      "------------------------------\n",
      "['Dept_26', 0.002076587782587236, 17363.583669989326, -9602.458544116153, 3.826971712288828e-46]\n",
      "Walmart: Weekly_Sales~Dept_27\n",
      "------------------------------\n",
      "['Dept_27', 0.005726592158344035, 17456.301875447327, -15946.134420903336, 3.2781918046249996e-124]\n",
      "Walmart: Weekly_Sales~Dept_28\n",
      "------------------------------\n",
      "['Dept_28', 0.006460390355530143, 17470.78432272922, -16937.007259793703, 6.373739588490596e-140]\n",
      "Walmart: Weekly_Sales~Dept_29\n",
      "------------------------------\n",
      "['Dept_29', 0.0033053011287481615, 17400.302269808846, -12114.704060019776, 2.033335788087451e-72]\n",
      "Walmart: Weekly_Sales~Dept_3\n",
      "------------------------------\n",
      "['Dept_3', 0.0003222695751431415, 17278.524876515672, -3782.831065327327, 1.958969099180746e-08]\n",
      "Walmart: Weekly_Sales~Dept_30\n",
      "------------------------------\n",
      "['Dept_30', 0.004072040259943788, 17419.769438849085, -13446.62598430488, 8.193116382242726e-89]\n",
      "Walmart: Weekly_Sales~Dept_31\n",
      "------------------------------\n",
      "['Dept_31', 0.005005522094079784, 17441.13498221122, -14908.43255563916, 8.842056755184766e-109]\n",
      "Walmart: Weekly_Sales~Dept_32\n",
      "------------------------------\n",
      "['Dept_32', 0.0016077857037104515, 17346.729462705778, -8449.312539629707, 4.1295999197783027e-36]\n",
      "Walmart: Weekly_Sales~Dept_33\n",
      "------------------------------\n",
      "['Dept_33', 0.002784809894146867, 17385.76393189434, -11120.00724658071, 2.7340039736809092e-61]\n",
      "Walmart: Weekly_Sales~Dept_34\n",
      "------------------------------\n",
      "['Dept_34', 0.0001972050585780094, 17266.486013027825, -2959.1454955457366, 1.119549562021644e-05]\n",
      "Walmart: Weekly_Sales~Dept_35\n",
      "------------------------------\n",
      "['Dept_35', 0.00474061163461259, 17435.290589778975, -14508.565764605493, 4.1105860786983957e-103]\n",
      "Walmart: Weekly_Sales~Dept_36\n",
      "------------------------------\n",
      "['Dept_36', 0.005434146002674667, 17450.19219282233, -15538.983193522608, 5.954835884723395e-118]\n",
      "Walmart: Weekly_Sales~Dept_37\n",
      "------------------------------\n",
      "['Dept_37', 0.0025958758139296156, 17344.424916014475, -13819.396722541303, 2.996954188821535e-57]\n",
      "Walmart: Weekly_Sales~Dept_38\n",
      "------------------------------\n",
      "['Dept_38', 0.07579114582447921, 16375.343542615232, 58011.825247599714, 0.0]\n",
      "Walmart: Weekly_Sales~Dept_39\n",
      "------------------------------\n",
      "['Dept_39', 2.3700381518332314e-05, 17224.115706707285, -17221.931706710508, 0.12781943154703523]\n",
      "Walmart: Weekly_Sales~Dept_4\n",
      "------------------------------\n",
      "['Dept_4', 0.0034076665890867552, 17043.44793328422, 12300.870367415959, 1.3168731505054074e-74]\n",
      "Walmart: Weekly_Sales~Dept_40\n",
      "------------------------------\n",
      "['Dept_40', 0.027639335983986713, 16711.205919364307, 35032.49722049894, 0.0]\n",
      "Walmart: Weekly_Sales~Dept_41\n",
      "------------------------------\n",
      "['Dept_41', 0.00515967031711817, 17444.464716157217, -15136.249226647817, 4.450194151237422e-112]\n",
      "Walmart: Weekly_Sales~Dept_42\n",
      "------------------------------\n",
      "['Dept_42', 0.0024518127516028887, 17375.737392878265, -10434.002665606222, 3.608683095314271e-54]\n",
      "Walmart: Weekly_Sales~Dept_44\n",
      "------------------------------\n",
      "['Dept_44', 0.003564652608089469, 17407.117892831597, -12581.021361363924, 5.794012054298755e-78]\n",
      "Walmart: Weekly_Sales~Dept_45\n",
      "------------------------------\n",
      "['Dept_45', 0.002514332252627982, 17316.729329976366, -17291.746588956066, 1.6610775907208424e-55]\n",
      "Walmart: Weekly_Sales~Dept_46\n",
      "------------------------------\n",
      "['Dept_46', 0.0005857429892847099, 17148.696365380805, 5099.890403850537, 3.696484641281715e-14]\n",
      "Walmart: Weekly_Sales~Dept_47\n",
      "------------------------------\n",
      "['Dept_47', 0.0008380879875801162, 17254.313959022347, -17276.570834021135, 1.3403839868341057e-19]\n",
      "Walmart: Weekly_Sales~Dept_48\n",
      "------------------------------\n",
      "['Dept_48', 0.003288333612542216, 17358.02132720285, -15736.636828398998, 4.688000849326583e-72]\n",
      "Walmart: Weekly_Sales~Dept_49\n",
      "------------------------------\n",
      "['Dept_49', 0.0012740046164011476, 17320.059712280057, -8511.388337616816, 5.850070847610682e-29]\n",
      "Walmart: Weekly_Sales~Dept_5\n",
      "------------------------------\n",
      "['Dept_5', 0.0019830111724014055, 17086.086192575367, 9383.608373858831, 3.8446007341138244e-44]\n",
      "Walmart: Weekly_Sales~Dept_50\n",
      "------------------------------\n",
      "['Dept_50', 0.00038476773482964965, 17242.213617241236, -12984.553337524061, 8.457846669962425e-10]\n",
      "Walmart: Weekly_Sales~Dept_51\n",
      "------------------------------\n",
      "['Dept_51', 0.0009622097452928191, 17259.00403099267, -17239.154769910725, 2.8743494744563305e-22]\n",
      "Walmart: Weekly_Sales~Dept_52\n",
      "------------------------------\n",
      "['Dept_52', 0.004959368919248641, 17440.128090427257, -14839.542146372709, 8.589982683461106e-108]\n",
      "Walmart: Weekly_Sales~Dept_54\n",
      "------------------------------\n",
      "['Dept_54', 0.005940026753230132, 17445.136520960416, -17340.70695227195, 8.844730791263635e-129]\n",
      "Walmart: Weekly_Sales~Dept_55\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dept_55', 0.0007743525651670025, 17308.93951280482, -5863.7664498684135, 3.156079026712965e-18]\n",
      "Walmart: Weekly_Sales~Dept_56\n",
      "------------------------------\n",
      "['Dept_56', 0.003998356193936625, 17417.844915932816, -13333.600672234525, 3.0843061773385873e-87]\n",
      "Walmart: Weekly_Sales~Dept_58\n",
      "------------------------------\n",
      "['Dept_58', 0.0023161262386034442, 17350.908474383647, -11729.00211757625, 2.8784633027651396e-51]\n",
      "Walmart: Weekly_Sales~Dept_59\n",
      "------------------------------\n",
      "['Dept_59', 0.005712497484076096, 17446.583507526837, -16579.769971866, 6.566469728140406e-124]\n",
      "Walmart: Weekly_Sales~Dept_6\n",
      "------------------------------\n",
      "['Dept_6', 0.0032769368014491373, 17399.54088705412, -12062.611103838472, 8.215992519568759e-72]\n",
      "Walmart: Weekly_Sales~Dept_60\n",
      "------------------------------\n",
      "['Dept_60', 0.006019028408300819, 17451.171553099353, -17115.139381187957, 1.8002635285339678e-130]\n",
      "Walmart: Weekly_Sales~Dept_67\n",
      "------------------------------\n",
      "['Dept_67', 0.0021961100427826397, 17367.566176809232, -9874.937204782302, 1.062003862880003e-48]\n",
      "Walmart: Weekly_Sales~Dept_7\n",
      "------------------------------\n",
      "['Dept_7', 0.002237635791705772, 17077.546837847076, 9967.86146984591, 1.3737858577799742e-49]\n",
      "Walmart: Weekly_Sales~Dept_71\n",
      "------------------------------\n",
      "['Dept_71', 0.003801156419492857, 17413.119951456825, -12991.675496912678, 5.081613145564501e-83]\n",
      "Walmart: Weekly_Sales~Dept_72\n",
      "------------------------------\n",
      "['Dept_72', 0.041194845769055854, 16598.13088757267, 42768.96437816511, 0.0]\n",
      "Walmart: Weekly_Sales~Dept_74\n",
      "------------------------------\n",
      "['Dept_74', 0.0001573703187435216, 17261.871642481514, -2643.435425698709, 8.709088250509164e-05]\n",
      "Walmart: Weekly_Sales~Dept_77\n",
      "------------------------------\n",
      "['Dept_77', 0.0001297971112507179, 17228.196508025776, -16736.937197681695, 0.0003657104708401241]\n",
      "Walmart: Weekly_Sales~Dept_78\n",
      "------------------------------\n",
      "['Dept_78', 0.0002559266365927959, 17232.742527483766, -17224.98474970486, 5.609003381400684e-07]\n",
      "Walmart: Weekly_Sales~Dept_79\n",
      "------------------------------\n",
      "['Dept_79', 0.0008525321753306558, 17133.30929280461, 6152.65669320972, 6.553548437448634e-20]\n",
      "Walmart: Weekly_Sales~Dept_8\n",
      "------------------------------\n",
      "['Dept_8', 0.009590041812660322, 16921.62848012112, 20635.621051348964, 4.912665622256794e-207]\n",
      "Walmart: Weekly_Sales~Dept_80\n",
      "------------------------------\n",
      "['Dept_80', 0.0004631526498690697, 17279.42709277222, -5327.248410602351, 1.6701314237514486e-11]\n",
      "Walmart: Weekly_Sales~Dept_81\n",
      "------------------------------\n",
      "['Dept_81', 0.00019357799158425948, 17266.086428445466, -2931.8063655087926, 1.348360492249702e-05]\n",
      "Walmart: Weekly_Sales~Dept_82\n",
      "------------------------------\n",
      "['Dept_82', 1.8630253960982834e-05, 17236.52913286103, -909.529272721377, 0.17698796934462266]\n",
      "Walmart: Weekly_Sales~Dept_83\n",
      "------------------------------\n",
      "['Dept_83', 0.0028121876795679235, 17359.442645084677, -13339.701684124082, 7.1025732071070835e-62]\n",
      "Walmart: Weekly_Sales~Dept_85\n",
      "------------------------------\n",
      "['Dept_85', 0.0051814143359009135, 17444.930380877322, -15168.109485773806, 1.5244597370430835e-112]\n",
      "Walmart: Weekly_Sales~Dept_87\n",
      "------------------------------\n",
      "['Dept_87', 0.00027483464792166235, 17172.17720658858, 3493.3575206843016, 2.1508574898746194e-07]\n",
      "Walmart: Weekly_Sales~Dept_9\n",
      "------------------------------\n",
      "['Dept_9', 0.002757910506046457, 17061.494111649306, 11066.171035204607, 1.0279172882304201e-60]\n",
      "Walmart: Weekly_Sales~Dept_90\n",
      "------------------------------\n",
      "['Dept_90', 0.01182931346445415, 16888.26159331594, 22918.546112979573, 3.6091022188037108e-255]\n",
      "Walmart: Weekly_Sales~Dept_91\n",
      "------------------------------\n",
      "['Dept_91', 0.00464827613400387, 17013.255902975834, 14366.575299822414, 3.882217574023159e-101]\n",
      "Walmart: Weekly_Sales~Dept_92\n",
      "------------------------------\n",
      "['Dept_92', 0.07102009323695047, 16402.464701013316, 56156.225935354945, 0.0]\n",
      "Walmart: Weekly_Sales~Dept_93\n",
      "------------------------------\n",
      "['Dept_93', 0.008524988385405274, 16985.60571564296, 23179.92956850495, 3.554190578449548e-184]\n",
      "Walmart: Weekly_Sales~Dept_94\n",
      "------------------------------\n",
      "['Dept_94', 0.005213165663129682, 17025.601844042794, 17066.45026539912, 3.1894242217433675e-113]\n",
      "Walmart: Weekly_Sales~Dept_95\n",
      "------------------------------\n",
      "['Dept_95', 0.07371073588413235, 16387.06151396646, 57210.09475876561, 0.0]\n",
      "Walmart: Weekly_Sales~Dept_96\n",
      "------------------------------\n",
      "['Dept_96', 4.968026192320174e-06, 17216.774233923574, 498.16603400402346, 0.48569215087851547]\n",
      "Walmart: Weekly_Sales~Dept_97\n",
      "------------------------------\n",
      "['Dept_97', 2.4427709407137677e-05, 17208.862313953738, 1101.2271222251175, 0.12211747335804243]\n",
      "Walmart: Weekly_Sales~Dept_98\n",
      "------------------------------\n",
      "['Dept_98', 0.0014371721822464822, 17322.55785072315, -9352.830208760563, 1.8628055116120896e-32]\n",
      "Walmart: Weekly_Sales~Dept_99\n",
      "------------------------------\n",
      "['Dept_99', 0.0008903819289346471, 17257.129764035977, -16833.360474696725, 1.0056165607766711e-20]\n",
      "Walmart: Weekly_Sales~Type_A\n",
      "------------------------------\n",
      "['Type_A', 0.04951528165205288, 11368.220523851567, 11263.248508393282, 0.0]\n",
      "Walmart: Weekly_Sales~Type_B\n",
      "------------------------------\n",
      "['Type_B', 0.04951528165205288, 22631.469032244888, -11263.248508393295, 0.0]\n",
      "Walmart: Weekly_Sales~binned_markdown_1_0-20%\n",
      "------------------------------\n"
     ]
    },
    {
     "ename": "PatsyError",
     "evalue": "Error evaluating factor: NameError: name 'binned_markdown_1_0' is not defined\n    Weekly_Sales~binned_markdown_1_0-20%\n                 ^^^^^^^^^^^^^^^^^^^",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/patsy/compat.py\u001b[0m in \u001b[0;36mcall_and_wrap_exc\u001b[0;34m(msg, origin, f, *args, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/patsy/eval.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, expr, source_name, inner_namespace)\u001b[0m\n\u001b[1;32m    165\u001b[0m         return eval(code, {}, VarLookupDict([inner_namespace]\n\u001b[0;32m--> 166\u001b[0;31m                                             + self._namespaces))\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'binned_markdown_1_0' is not defined",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mPatsyError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-0bfd1bebb833>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Weekly_Sales~'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformula\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mX_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py\u001b[0m in \u001b[0;36mfrom_formula\u001b[0;34m(cls, formula, data, subset, drop_cols, *args, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         tmp = handle_formula_data(data, None, formula, depth=eval_env,\n\u001b[0;32m--> 155\u001b[0;31m                                   missing=missing)\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesign_info\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/statsmodels/formula/formulatools.py\u001b[0m in \u001b[0;36mhandle_formula_data\u001b[0;34m(Y, X, formula, depth, missing)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_using_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             result = dmatrices(formula, Y, depth, return_type='dataframe',\n\u001b[0;32m---> 65\u001b[0;31m                                NA_action=na_action)\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             result = dmatrices(formula, Y, depth, return_type='dataframe',\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/patsy/highlevel.py\u001b[0m in \u001b[0;36mdmatrices\u001b[0;34m(formula_like, data, eval_env, NA_action, return_type)\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0meval_env\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEvalEnvironment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_env\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreference\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     (lhs, rhs) = _do_highlevel_design(formula_like, data, eval_env,\n\u001b[0;32m--> 310\u001b[0;31m                                       NA_action, return_type)\n\u001b[0m\u001b[1;32m    311\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlhs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mPatsyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model is missing required outcome variables\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/patsy/highlevel.py\u001b[0m in \u001b[0;36m_do_highlevel_design\u001b[0;34m(formula_like, data, eval_env, NA_action, return_type)\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     design_infos = _try_incr_builders(formula_like, data_iter_maker, eval_env,\n\u001b[0;32m--> 165\u001b[0;31m                                       NA_action)\n\u001b[0m\u001b[1;32m    166\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdesign_infos\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         return build_design_matrices(design_infos, data,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/patsy/highlevel.py\u001b[0m in \u001b[0;36m_try_incr_builders\u001b[0;34m(formula_like, data_iter_maker, eval_env, NA_action)\u001b[0m\n\u001b[1;32m     68\u001b[0m                                       \u001b[0mdata_iter_maker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                                       \u001b[0meval_env\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                                       NA_action)\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/patsy/build.py\u001b[0m in \u001b[0;36mdesign_matrix_builders\u001b[0;34m(termlists, data_iter_maker, eval_env, NA_action)\u001b[0m\n\u001b[1;32m    694\u001b[0m                                                    \u001b[0mfactor_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m                                                    \u001b[0mdata_iter_maker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m                                                    NA_action)\n\u001b[0m\u001b[1;32m    697\u001b[0m     \u001b[0;31m# Now we need the factor infos, which encapsulate the knowledge of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m     \u001b[0;31m# how to turn any given factor into a chunk of data:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/patsy/build.py\u001b[0m in \u001b[0;36m_examine_factor_types\u001b[0;34m(factors, factor_states, data_iter_maker, NA_action)\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_iter_maker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfactor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamine_needed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfactor_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfactor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfactor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcat_sniffers\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mguess_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mfactor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcat_sniffers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/patsy/eval.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, memorize_state, data)\u001b[0m\n\u001b[1;32m    564\u001b[0m         return self._eval(memorize_state[\"eval_code\"],\n\u001b[1;32m    565\u001b[0m                           \u001b[0mmemorize_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m                           data)\n\u001b[0m\u001b[1;32m    567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0m__getstate__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mno_pickling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/patsy/eval.py\u001b[0m in \u001b[0;36m_eval\u001b[0;34m(self, code, memorize_state, data)\u001b[0m\n\u001b[1;32m    549\u001b[0m                                  \u001b[0mmemorize_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"eval_env\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m                                  \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                                  inner_namespace=inner_namespace)\n\u001b[0m\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmemorize_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhich_pass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/patsy/compat.py\u001b[0m in \u001b[0;36mcall_and_wrap_exc\u001b[0;34m(msg, origin, f, *args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m                                  origin)\n\u001b[1;32m     42\u001b[0m             \u001b[0;31m# Use 'exec' to hide this syntax from the Python 2 parser:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"raise new_exc from e\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;31m# In python 2, we just let the original exception escape -- better\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/patsy/compat.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mPatsyError\u001b[0m: Error evaluating factor: NameError: name 'binned_markdown_1_0' is not defined\n    Weekly_Sales~binned_markdown_1_0-20%\n                 ^^^^^^^^^^^^^^^^^^^"
     ]
    }
   ],
   "source": [
    "\n",
    "col_names = df.describe().columns.drop(['Weekly_Sales'])\n",
    "results = [['ind_var', 'r_squared', 'intercept', 'slope', 'p-value' ]]\n",
    "for idx, val in enumerate(col_names):\n",
    "    print (\"Walmart: Weekly_Sales~\" + val)\n",
    "    print (\"------------------------------\")\n",
    "\n",
    "    f = 'Weekly_Sales~' + val\n",
    "    model = smf.ols(formula=f, data=df).fit()\n",
    "    X_new = pd.DataFrame({val: [df[val].min(), df[val].max()]});\n",
    "    preds = model.predict(X_new)\n",
    "    results.append([val, model.rsquared, model.params[0], model.params[1], model.pvalues[1] ])\n",
    "    print(results[idx+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think about your results. \n",
    "- What do the parameter estimates mean? Do they make sense? \n",
    "- What do the p-values tell us?\n",
    "- What does the R-squared tell us?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our R-squared values are low, let's try to solve this\n",
    "\n",
    "Something we haven't considered before, is taking log-transformations to make certain data less skewed. Let's take a quick look at our summarizing histograms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly the most problematic variable in terms of skewness seems to be weekly sales itself. Does it make sense to log-transform this variable? It definitely doesn't hurt to try! Let's have a look below. what do you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's right, we have some negative `Weekly_Sales` values! Let's check how many we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems negligibe considering we have almost 100,000 observations. Let's remove these 224 rows so we can take the log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have another look at the histogram. What do you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's repeat what we did before, yet now with the log(Weekly_Sales) as the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- compare and contract the results with the results obtained when we did not take the log(sales)\n",
    "- Which one would you want to proceed with based on this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a model with each categorical variable as a predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use it on the log-transformed, and the regular `Weekly_Sales`\n",
    "- put all categories for one categorical variable in 1 model, so we want 4 models.\n",
    "- remember that we have 4 categorical variables: `Store`,  `Dept`, `IsHoliday` and `Type`( we're for now ignoring the `binned_markdown` categories, you can add then later on as an extension)\n",
    "- IMPORTANT: remember that we made dummies for `Type`, `Dept` and `Store` columns. You'll need to drop 1 column for each of these if you want good results. The reason for this is that singularity will occur and . This is related to what we mentioned earlier on in section 11. Don't worry about the \"why\" for now, just make sure to drop 1 column and you should be fine! The parameter value for the dropper \"base category\" will be absorbed in the intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's drop a few columns in our data set based on our findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's stick with our `walmart_log` data, as it seemed like it was generally resulting in higher R-squared values.\n",
    "- Let's drop continuous variables which resulted in single linear models with a R-squared value <0.01 for the `walmart_log models`.\n",
    "- Let's make sure to drop 1 column for each categorical variable we end up using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From here on out, use Feature ranking with recursive feature elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a matrix X and y containing the predictors and target for our model. Let's use Scikit-Learn's RFE function, documentation again [here](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a for loop using `RFE` where we look at the 5, 15, 25,... up until 85 best features to be selected according to the feature ranking algorithm. Store the R-squared and the adjusted-R-squareds for all these models in a list. What do you see? No need to perform a train-test-split for now- that will be next!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference between $R^2$ and adjusted $R^2$ is negligible, and seems to continue to be going up as we include more features. Remember though that we're likely overfitting when including 85 features. In order to identify this, let's rerun a similar experiment, but using a train test split!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Including a train-test-split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a similar for loop to what we did before. Except, this time\n",
    "- Use a train test split of 20-80\n",
    "- Instead of looking at $R^2$ and $R^2_{adj}$, look at the MSE for train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we see is that both MSE keeps improving when we add variables. It seems like a bigger model improves our performance, and the test and train performance don't really diverge. It is important to note however that is not an unusual result. The performance measures used typically will show this type of behavior. In order to really be able to balance the curse of dimensionality (which will become more important in machine learning), we need other information criteria such as AIC and BIC. You'll learn about them later! Now, let's perform cross-validation on our model with 85 predictors!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10-fold cross validation with the final model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a 10-fold cross-validation and store the (negative) MSEs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running our 10-fold cross-validation highlights some issues for sure! Have a look at your list of 10 MSEs. Where most MSEs are manageable, some are very high. The cure of dimensionality is already pretty clear here. The issue is that we have many (dummy) categorical variables that result in columns with many zeroes and few ones. This means that for some folds, there is a risk of ending up with columns that almost exclusively contain 0's for prediction, which might cause weird results. Looking at this, a model with less predictors might make sense again. This is where we conclude for now. It's up to you now to explore other model options! Additionally, it is encouraged to try some of the \"level up\" exercises below. Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Level up - Optional\n",
    "\n",
    "\n",
    "- You could argue that **throwing out negative sales figures is problematic**, because these are probably the types of observations a stakeholder would be very interested in knowing. Repeat your analysis, but now, instead of removing the rows with negative sales, replace their sales with a slightly positive value (eg. 1), so they have an existing and finite value. Does the result change?\n",
    "\n",
    "- Go back and log-transform `CPI` and `Size` before standardizing it (we did this a few lessons ago). Look at the histogram and see if there is an improvement.\n",
    "- You might have noticed we ignored `binned_markdown` throughout. Add it in the model and see how it changes the results!\n",
    "\n",
    "- Try other feature selection methods such as stepwise selection and forward selection seen in section 11.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations, you made it to the end of the last section in this module. Now it's time for a big project on multiple linear regression!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
